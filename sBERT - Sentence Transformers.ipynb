{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "limited-coordinator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sentence-transformers in /home/majarall/.local/lib/python3.8/site-packages (2.2.0)\n",
      "Requirement already satisfied: sentencepiece in /home/majarall/.local/lib/python3.8/site-packages (from sentence-transformers) (0.1.96)\n",
      "Collecting torch>=1.6.0\n",
      "  Downloading torch-1.11.0-cp38-cp38-manylinux1_x86_64.whl (750.6 MB)\n",
      "     |████████████████████████████████| 750.6 MB 27 kB/s                  |███████████████████▊            | 463.1 MB 17.5 MB/s eta 0:00:17█████▍       | 572.1 MB 21.3 MB/s eta 0:00:09�█████      | 612.3 MB 20.3 MB/s eta 0:00:07\n",
      "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /home/majarall/.local/lib/python3.8/site-packages (from sentence-transformers) (4.17.0)\n",
      "Requirement already satisfied: tqdm in /home/majarall/.local/lib/python3.8/site-packages (from sentence-transformers) (4.59.0)\n",
      "Requirement already satisfied: nltk in /home/majarall/.local/lib/python3.8/site-packages (from sentence-transformers) (3.5)\n",
      "Requirement already satisfied: numpy in /home/majarall/.local/lib/python3.8/site-packages (from sentence-transformers) (1.19.5)\n",
      "Requirement already satisfied: torchvision in /home/majarall/.local/lib/python3.8/site-packages (from sentence-transformers) (0.10.0)\n",
      "Requirement already satisfied: scikit-learn in /home/majarall/.local/lib/python3.8/site-packages (from sentence-transformers) (0.24.1)\n",
      "Requirement already satisfied: scipy in /home/majarall/.local/lib/python3.8/site-packages (from sentence-transformers) (1.6.2)\n",
      "Requirement already satisfied: huggingface-hub in /home/majarall/.local/lib/python3.8/site-packages (from sentence-transformers) (0.4.0)\n",
      "Requirement already satisfied: typing-extensions in /home/majarall/.local/lib/python3.8/site-packages (from torch>=1.6.0->sentence-transformers) (3.7.4.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/majarall/.local/lib/python3.8/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2021.3.17)\n",
      "Requirement already satisfied: filelock in /usr/lib/python3/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.12)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/majarall/.local/lib/python3.8/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (20.9)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /home/majarall/.local/lib/python3.8/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.12.0)\n",
      "Requirement already satisfied: requests in /home/majarall/.local/lib/python3.8/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2.26.0)\n",
      "Requirement already satisfied: sacremoses in /home/majarall/.local/lib/python3.8/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.0.44)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (5.3.1)\n",
      "Requirement already satisfied: joblib in /home/majarall/.local/lib/python3.8/site-packages (from nltk->sentence-transformers) (1.0.1)\n",
      "Requirement already satisfied: click in /home/majarall/.local/lib/python3.8/site-packages (from nltk->sentence-transformers) (7.1.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/majarall/.local/lib/python3.8/site-packages (from scikit-learn->sentence-transformers) (2.1.0)\n",
      "  Using cached torch-1.9.0-cp38-cp38-manylinux1_x86_64.whl (831.4 MB)\n",
      "Requirement already satisfied: pillow>=5.3.0 in /home/majarall/.local/lib/python3.8/site-packages (from torchvision->sentence-transformers) (8.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/majarall/.local/lib/python3.8/site-packages (from packaging>=20.0->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2019.11.28)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/majarall/.local/lib/python3.8/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.0.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.25.8)\n",
      "Requirement already satisfied: six in /home/majarall/.local/lib/python3.8/site-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.15.0)\n",
      "Installing collected packages: torch\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.4.0\n",
      "    Uninstalling torch-1.4.0:\n",
      "      Successfully uninstalled torch-1.4.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spacybert 1.0.1 requires spacy<3.0.0,>=2.2.1, but you have spacy 3.0.5 which is incompatible.\u001b[0m\n",
      "Successfully installed torch-1.9.0\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporated-boring",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install pytorch torchvision torchaudio cudatoolkit=10.2 -c pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "organic-failure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "#sbert.net\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fifty-rendering",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.18893567,  0.18380427, -0.5132157 , ..., -0.9622861 ,\n",
       "         0.16144875, -0.18547589],\n",
       "       [-0.0254809 , -0.06504318,  0.85490644, ..., -0.08297264,\n",
       "        -0.2698283 , -0.09522374],\n",
       "       [-0.05365554, -0.1009286 ,  0.9991935 , ...,  1.1357747 ,\n",
       "         0.01794523, -0.24008028],\n",
       "       [ 0.21320082,  1.8518618 ,  0.36619136, ...,  0.00735281,\n",
       "         0.3132772 ,  0.41728267],\n",
       "       [ 0.17712384,  1.5110037 ,  0.96275413, ...,  0.07071581,\n",
       "        -0.27150536,  0.34254614]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = [\n",
    "    \"the fifty mannequin heads floating in the pool kind of freaked them out\",\n",
    "    \"she swore she just saw her sushi move\",\n",
    "    \"he embraced his new life as an eggplant\",\n",
    "    \"my dentist tells me that chewing bricks is very bad for your teeth\",\n",
    "    \"the dental specialist recommended an immediate stop to flossing with construction materials\"\n",
    "]\n",
    "\n",
    "embedding = model.encode(sentences)\n",
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dramatic-question",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 768)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "heavy-society",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.00000024 0.         0.         0.         0.        ]\n",
      " [0.40914297 1.00000024 0.         0.         0.        ]\n",
      " [0.10909013 0.44547984 1.         0.         0.        ]\n",
      " [0.50074863 0.30693924 0.20791626 0.99999982 0.        ]\n",
      " [0.29936206 0.38607216 0.28499267 0.63849503 1.00000072]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAAD8CAYAAADUv3dIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAlmklEQVR4nO3deXxU1d3H8c9vkrBvsmgSEgUFKyibImK1iiiLWBYfW9xQqyhP61K0FeqOoliqLS0+tVpqLe5K1SoorYLFHSTsSqjsQjaWsMmezJznj8SYAMkkZnLvzO337eu+XnPvPXPmdxzyy8m5595jzjlERMQbIb8DEBH5b6KkKyLiISVdEREPKemKiHhISVdExENKuiIiHlLSFRGphJk9bWabzeyLSs6bmT1mZqvNbJmZnRqtTiVdEZHKTQUGVnH+QqBj6TYKeCJahUq6IiKVcM59CGyroshQ4FlXYh7QwszSqqozOZYBHknR1rWBu+WtYfoP/A5BJJCKD+ZabeuoSc6p1+aE/6Wkh/qNKc65KTX4uLbAxnL7OaXH8it7Q50nXRGReFWaYGuSZGtNSVdEgiUS9vLTcoHMcvsZpccqpTFdEQmWcHH1t9qbDlxdOouhN7DTOVfp0AKopysiAeNcJGZ1mdlLQB+gtZnlAOOAlJLPcU8CM4FBwGpgL3BttDqVdEUkWCKxS7rOucujnHfATTWpU0lXRIIlhj3duqCkKyLB4u2FtBpT0hWRYFFPV0TEOy42sxLqjJKuiARLDC+k1QUlXREJFg0viIh4SBfSREQ8pJ6uiIiHdCFNRMRDupAmIuId5zSmKyLinTgf0w3Eox3veXgS51x0GcNG/NTvUGJqQP8+LP/iQ/6T/TFjx9TomRpxLYjtCmKbIEHbFYlUf/NBIJLusEH9eHLSQ36HEVOhUIjHJk/gh4NH0KXbeVx66TA6derod1i1FsR2BbFNkMDtcpHqbz6ImnTN7CQz+1XpMsOPlb7u5EVw1dWzexeaN2vqdxgx1ev0HqxZs5516zZQVFTEtGlvMmTwAL/DqrUgtiuIbYIEble4qPqbD6pMumb2K+BlwID5pZsBL5nZHXUf3n+v9LapbMzJK9vPyc0nPT3Vx4hiI4jtCmKbIIHbFefDC9EupI0ETnbOVfiVYGaTgOXAxCO9ycxGUbrC5p9+9xDXX13lc4BFRGInzi+kRUu6ESAd+OqQ42ml546o/AqbQVyC3Qt5uQVkZqSX7We0TSMvr8DHiGIjiO0KYpsggdsV5/N0o43p3gq8Z2b/NLMppdu/gPeA0XUe3X+xrAVL6NChPe3aZZKSksLw4UOZ8da7fodVa0FsVxDbBAncrkQeXnDO/cvMTgR6AW1LD+cCWS6OZiCPGTeRrMXL2LFjF+cPG8GNI6/ikkQY8K9COBxm9K33MPPtF0kKhZj6zCtkZ6/0O6xaC2K7gtgmSNx2OZ8ukFWXlayrVneCOLzQMP0HfocgEkjFB3OttnXsm/NUtXNOw/Our/Xn1ZTuSBORYInzMV0lXREJlgSfvSAikljU0xUR8ZB6uiIiHirWQ8xFRLyjnq6IiIc0pisi4iH1dEVEPKSeroiIh9TTFRHxkGYviIh4qI6fJ1NbSroiEiwa0xUR8VCcJ91ArAYsIlImhqsBm9lAM/vSzFYfaV1IMzvWzOaY2WIzW2Zmg6LVqZ6uiARLODbrK5hZEvA40A/IAbLMbLpzLrtcsXuAac65J8ysMzATaFdVvXWedKd1va+uP8Jz+/I+8juEOqGHs0sgxG54oRew2jm3FsDMXgaGAuWTrgOalb5uDuQRhXq6IhIsNUi65VcuLzWldGFdKFmibGO5cznAGYdUcT/wrpndAjQGLoj2mUq6IhIsNbg5ovzK5d/R5cBU59zvzOxM4DkzO8W5yoNQ0hWRQHGRmM3TzQUyy+1nlB4rbyQwEMA5N9fMGgCtgc2VVarZCyISLLFbgj0L6Ghm7c2sHnAZMP2QMhuA8wHMrBPQANhSVaXq6YpIsMRo9oJzrtjMbgbeAZKAp51zy81sPLDAOTcd+CXwFzO7jZKLaj9xUZZYV9IVkWCJ4c0RzrmZlEwDK3/svnKvs4GzalKnkq6IBEuc35GmpCsiwaIH3oiIeEg9XRERD8VuylidUNIVkWCJ0eyFuqKkKyKB4jS8ICLiIQ0viIh4SAtTioh4SD1dEREPFetCmoiId+J8eCFhnjKW1qcrgz96lCGf/I7ONw+utFzmoNO5Mu95WnZtD0C9o5pw/t/vYviqp+g54Wqvwq21ex6exDkXXcawET/1O5SYG9C/D8u/+JD/ZH/M2DE3+R1OTASxTZCg7Yq46m8+SIikayHj9IevYc6Vj/BWn7G0G9qbZh3TDyuX3LgBJ10/gK0LV5cdC+8vYtmjr7J4/Itehlxrwwb148lJD/kdRsyFQiEemzyBHw4eQZdu53HppcPo1Kmj32HVShDbBInbLheJVHvzQ0Ik3VY9TuDr9ZvYvWELkaIwX705j8wBpx1WrtvYH7H88bcIHygqOxbed4At81dWOJYIenbvQvNmTf0OI+Z6nd6DNWvWs27dBoqKipg27U2GDB7gd1i1EsQ2QQK3Sz3d2muYehR787aV7e/N30bDtKMqlDmqSzsapbck770lHkcnNZHeNpWNOd+u3ZeTm096eqqPEdVeENsECdyuoCZdM7s2loHUihmnjbuSRQ8k1hCCiNSBcLj6mw9q09N9oLITZjbKzBaY2YJ/711Vi48osa9gO43SW5btN0pryb787WX7KU0a0PykDC547W6GfvZ7Wp96AudO/UXZxTSJH3m5BWRmfDsen9E2jby8Ah8jqr0gtgkSt10u4qq9+aHKpGtmyyrZPgeOqex9zrkpzrmezrmefRvVfuC9cMlamrZPpXFmG0IpSRw3tDc57y4qO1/09T5eO+VnvHnGbbx5xm1sXbSGD34yiW3L1tX6syW2shYsoUOH9rRrl0lKSgrDhw9lxlvv+h1WrQSxTZDA7Yrz4YVo83SPAQYA2w85bsCndRLREbhwhAV3P0PfF8diSSHWvPwBO1fm0nXMJRQuXUduuQR8JEM/+z0pTRoSqpdM5oCevHf5RHatyqvyPX4bM24iWYuXsWPHLs4fNoIbR17FJYlwESOKcDjM6FvvYebbL5IUCjH1mVfIzl7pd1i1EsQ2QQK3K84feGNVraFmZn8F/uac+/gI5150zl0R7QNeSB8R3/fkfQfDl433O4Q60TD9B36HIP/lig/mWm3r+PrGC6udc5r+6Z+1/ryaqrKn65wbWcW5qAlXRMRzevaCiIh3XDi+hxeUdEUkWNTTFRHxjl9TwapLSVdEgkVJV0TEQ/E9pKukKyLB4orjO+sq6YpIsMR3zlXSFZFg0YU0EREvqacrIuId9XRFRLyknq6IiHdcsd8RVE1JV0QCJc5XYE+MNdJERKotUoMtCjMbaGZfmtlqM7ujkjLDzSzbzJabWdQ1w9TTFZFAiVVP18ySgMeBfkAOkGVm051z2eXKdATuBM5yzm03s6Oj1auerogEiotUf4uiF7DaObfWOXcQeBkYekiZG4DHnXPbAZxzm6NVWuc93YeKE2B5jxo66uS7/A6hTuzL+8jvEGJOq2H893Hh6i8GYWajgFHlDk1xzk0pfd0W2FjuXA5wxiFVnFhazydAEnC/c+5fVX2mhhdEJFBqMrxQmmCnRC1YuWSgI9AHyAA+NLMuzrkdVb1BRCQwXCRmy57lApnl9jNKj5WXA3zmnCsC1pnZSkqScFZllWpMV0QCJYZjullARzNrb2b1gMuA6YeUeYOSXi5m1pqS4Ya1VVWqnq6IBIpzsenpOueKzexm4B1Kxmufds4tN7PxwALn3PTSc/3NLBsIA2Occ4VV1aukKyKBEsubI5xzM4GZhxy7r9xrB/yidKsWJV0RCZRIDWYv+EFJV0QCJYYX0uqEkq6IBIqSroiIh1x8P05XSVdEgkU9XRERD8VqylhdUdIVkUAJa/aCiIh31NMVEfGQxnRFRDyk2QsiIh5ST1dExEPhSHw/PDG+oyt19nm9mfnp3/nXZ69x/S1XH3a+Z+8evDb7WT7P+5T+P+xb4dyUlyfz2ar3eOL5SV6FW22tz+vGOZ9M4tx5f+D4W4ZUWi71ol4M2vQyzbsdD0DDzDYMWP8sZ783kbPfm8gpj4z0KuRau+fhSZxz0WUMG/FTv0OJqQH9+7D8iw/5T/bHjB1zk9/hxEwitsu56m9+iPuebigU4t7fjGXkj29mU95mpr37DHPe+Yg1K9eVlcnLLeDOn4/nuhtHHPb+px9/ngYN63Pp1f/jZdjRhYyTJ17H/OET2J9XyFnvPMzmdxaye2XFZyQnNW5AuxsuZPvCVRWO7/1qEx+ff8TFSePasEH9uOKSIdz14G/9DiVmQqEQj02ewMBBl5OTk8+8uTOZ8da7rFixKvqb41iitisS57MXovZ0zewkMzvfzJoccnxg3YX1ra6nnsyGdTnkfJVHUVExM//xLn0HnlOhTN7GfFZmryYSOfyZbvM+ymLP7r1ehFojLU7twN51Bez7ajOuKEz+G59yzMCeh5U78Y7hrPnjdCL7i3yIMvZ6du9C82ZN/Q4jpnqd3oM1a9azbt0GioqKmDbtTYYMHuB3WLWWqO1yzqq9+aHKpGtmPwfeBG4BvjCz8ithPlyXgX3j6NQ2FORuKtvflL+ZY9LaePHRdapBakv25337rON9eduon9qyQplmXdrRML0VW2YvPuz9DY9tw1mzf80Z/7iPo844qc7jlcqlt01lY05e2X5Obj7p6ak+RhQbidquRB9euAE4zTm328zaAa+aWTvn3GSg0l8T5VfYTG1yHC0aRl0KXg5lRqcHrmbZ6CcOO3Vg03bmnHozRdt306xre06bejsfnXM7xbv3+RCoSHyJ9+GFaEk35JzbDeCcW29mfShJvMdRRdItv8Jmp6N71er3yeaCLaS2PaZs/5i0o9mUv6U2VcaF/QXbaJDeqmy/YXpLDhRsK9tPbtKApidlcMbrJQ+pr390c0579nYWXv1bdi5dS+TgbgB2LVvH3vWbaHxCGjuXVrk0k9SRvNwCMjPSy/Yz2qaRl1fgY0SxkajtSvTZC5vMrPs3O6UJ+IdAa6BLHcZV5vPF2Rx3fCZtj00nJSWZQRf3Z847H3nx0XVq5+I1ND4+lYbHtsFSkkgb9n02vbOw7Hzx1/uY3XkU759+C++ffgs7Fq4uS7j1WjWFUMnvvIbHHU3j41PZ+9Wmyj5K6ljWgiV06NCedu0ySUlJYfjwocx4612/w6q1RG2Xq8Hmh2g93auB4vIHnHPFwNVm9uc6i6qccDjMQ3c8ylOvPEYoKcTrL85g9ZdrueVXo/hiyQrmvPMRp3TvxP9NfYRmzZtxXv8fcMvYUQw+5zIAnps+heM7HEejxg2Zs2QG99w2gU/mzPMi9Cq5cITld/6NXi/fBUkhcl6aw+4vc+g49sfsXLqWzeUS8KFa9u5Ex7E/xhWHcRHHF2OfomjHHg+j/+7GjJtI1uJl7Nixi/OHjeDGkVdxSQJcnKlKOBxm9K33MPPtF0kKhZj6zCtkZ6/0O6xaS9R2xfvwgrk6Hk2u7fBCPPqdHe93CHWi33JPro16qmH6D/wOQWqg+GBurTPmJ6k/qnbOOavgVc8zdNzP0xURqYkYLgZcJ5R0RSRQXOXX+OOCkq6IBEpxnI/pKumKSKCopysi4iGN6YqIeEg9XRERD6mnKyLiobB6uiIi3onz1XqUdEUkWCLq6YqIeCfenzugpCsigaILaSIiHoqYhhdERDwT9juAKOL7EesiIjUUsepv0ZjZQDP70sxWm1mly2+b2SVm5szs8NVlD6GerogESqxmL5hZEvA40A/IAbLMbLpzLvuQck2B0cBn1am3zpPuc/XSoxdKMK8lB/MPhL+cOtrvEGJuX17iL+10JHo4e+ViOHuhF7DaObcWwMxeBoYC2YeUexD4DTCmOpUGM3uIyH+tmgwvmNkoM1tQbhtVrqq2wMZy+zmlx8qY2alApnPu7erGp+EFEQmUmkwZK79yeU2ZWQiYBPykJu9T0hWRQAnHbsZYLpBZbj+j9Ng3mgKnAO9byTS1VGC6mQ1xzi2orFIlXREJlBjeHJEFdDSz9pQk28uAK7456ZzbCbT+Zt/M3gduryrhgsZ0RSRgIjXYquKcKwZuBt4BVgDTnHPLzWy8mQ35rvGppysigRLLJdKcczOBmYccu6+Ssn2qU6eSrogEip69ICLioXi/DVhJV0QCRQ8xFxHxkIYXREQ8pKQrIuIhrRwhIuIhjemKiHhIsxdERDwUifMBBiVdEQkUXUgTEfFQfPdzEzTpNuvTg2MfuB6SQmx9aRYFj79e4XyrH/cl455rKCrYBsDmqW+z9aXZfoRapRPP7coP77uaUFKIrFfm8METMyqc73Xl+Zx5VT8ikQgH9xzgH3c+xebVuTRq0YQrnhhNRtcTWPTqh0wfN9WfBlSix7mnMvL+GwglhZj98ixe/9OrFc4PuX4oF1zen3BxmF3bdvHH2yezJXcLAPc+ez/f6/E9VixYwYRrx/sQ/Xdzz8OT+PCT+bQ8qgVvPP+k3+HEzID+fZg0aTxJoRBP/+0lHnn0cb9Diko93VgLhTj2of9l5RXjKMovpNPbj7Lj3fnsX5VTodj2GR+z4Z6/+BRkdBYyhoy/lr+O+DW7Cgq5afpDrJi1iM2rv31c59I3P2X+C+8B0OmCU7no3hH87ZrfUHSgiFm/e5VjvpdB6omZlX2EL0KhEKMe+in3X3kvhfmFPDJjEvNnfUbOqm8fwL92+Vpuv+gXHNx/gAEjLuTqu67ldzc9AsAbf36d+g3rM+DKC/1qwncybFA/rrhkCHc9+Fu/Q4mZUCjEY5MnMHDQ5eTk5DNv7kxmvPUuK1as8ju0KhVbfPd1E+7Rjo27d+TA+nwObtiEKypm25sf06L/GX6HVWOZ3TtQ+NUmtm/cTLgozNIZc+nU/7QKZQ7s3lf2ul6j+jhX8o+paN8BvlrwJcUHijyNuTo6du9I/vp8Nm3YRHFRMR/P+JBeh3w/X8z9nIP7DwCwcvGXtEprVXbu80+Wsa9cuxNFz+5daN6sqd9hxFSv03uwZs161q3bQFFREdOmvcmQwQP8DisqV4PND1F7umbWC3DOuSwz6wwMBP5T+sgzz9VLa8nB/K1l+wcLCmnSo+Nh5VpceCZNzjiZ/Wvz2Hj/0xSVe088aHbMUezMKyzb35W/jczuHQ4r1/uqfpx9/SCSUpJ56ooJXob4nbRMbcXWvG//XxfmF3Ji9xMrLX/Bpf1YNGehF6FJDaW3TWVjTl7Zfk5uPr1O7+FjRNUT78MLVfZ0zWwc8BjwhJn9Gvgj0Bi4w8zu9iC+72THrCw+P3MU2f1uZdeHS2j/h5/7HdJ3Nu+5Wfz23Nv418SX6HvLML/DialzL+7DCV078MafX49aVqS6Irhqb36INrzwI+As4BzgJmCYc+5BYABwaWVvKr/C5ut71scqVgAO5m+jXlrZChnUS23FwfxtFcqEd3yNO1gMwNaXZtOoywkxjSEWdm3aTvP0b/+sbpbWkp2btlVaftmMuXTu19OL0GplW0EhrdO//X5apbWicFPhYeW6nt2NH908nF+PfIji0u9K4ktebgGZGell+xlt08jLK/AxouqJ9+GFaEm32DkXds7tBdY453YBOOf2UUUv3jk3xTnX0znX838at4tdtMCepato0D6NeplHYynJtBx6Njtmza9QJuXoo8pet+h/OvtX5xxaje9ylq6hdbtUjspoQ1JKEt0Gn8mKWRX/zG7VLrXs9ff69mDr+vj/B79q6SrS2qdzdOYxJKckc/bgc8g65Ptpf/Lx/OzXN/HwyAfZWbjTp0glmqwFS+jQoT3t2mWSkpLC8OFDmfHWu36HFVWsluupK9HGdA+aWaPSpFt2lcfMmuNXzOEIG+79Cye+MA5CSRS+Mpv9KzeSfvvl7Fm6mp2zsjj6uoto0a8XLhymeMdu1t/2mC+hViUSjjD9vqlc9+wdWFKIBdPeZ/OqXC647Ufkfr6WFbMXceY1/elw1imEi4vZt3MPf//lE2XvH/vxZOo3aUhSSjKd+5/G01dNrDDzwS+RcIS/3Psk4557gFBSiPdemc3GlRu4/BdXsvrzVWTNms81d19Lg0YNGPPEHQBsydvCr0c+BMCEVyfS9oQMGjRuwF8++xuPj3mMJR8u9rNJ1TJm3ESyFi9jx45dnD9sBDeOvIpLEuCiU1XC4TCjb72HmW+/SFIoxNRnXiE7e6XfYUUVjvOZuvbNFfEjnjSr75w7cITjrYE059zn0T5gQcaw+P4/8B28ltzI7xDqxH8iX/sdQsxNWzTZ7xDqRMP0H/gdQp0oPphb68fVjG53WbVzzuT1L3v+eJwqe7pHSrilx7cC8TUdQEQEcHHe0028myNERKoQ71PGlHRFJFD0lDEREQ/Fd8pV0hWRgCmO87SrpCsigaILaSIiHtKFNBERD6mnKyLiIfV0RUQ8FK7iLtt4oKQrIoGieboiIh7SmK6IiIc0pisi4qF4H15IuIUpRUSq4mrwXzRmNtDMvjSz1WZ2xxHO/8LMss1smZm9Z2bHRatTSVdEAiXsXLW3qphZEvA4cCHQGbi8dHHe8hYDPZ1zXYFXgUeixaekKyKBEsOFKXsBq51za51zB4GXgaHlCzjn5pSurAMwD8iIVmmdj+lOS25Y1x/huY7FwfxdtTe5sd8hxNzu/73O7xDqxL68j/wOIW7V5EKamY0CRpU7NMU5N6X0dVtgY7lzOcAZVVQ3EvhntM/UhTQRCZSaTBkrTbBTohaMwsxGAD2Bc6OVVdIVkUCJ4eyFXCCz3H5G6bEKzOwC4G7g3MqWOCtPSVdEAqWqxXZrKAvoaGbtKUm2lwFXlC9gZj2APwMDnXObq1Opkq6IBEqslmB3zhWb2c3AO0AS8LRzbrmZjQcWOOemA48CTYC/mxnABufckKrqVdIVkUCJ5c0RzrmZwMxDjt1X7vUFNa1TSVdEAiWGwwt1QklXRAIl3m8DVtIVkUDRU8ZERDykh5iLiHhIwwsiIh5S0hUR8ZBmL4iIeEg9XRERD2n2goiIh8IuvldJU9IVkUDRmK6IiIc0plsHTjy3G0PvuxpLCjH/lTm8/8T0Cud7X3kBZ17VDxeJcGDPfl678yk2rz7sMZi+y+jTlTMfuApLCvHlS++z9PEZFc53GtGXzj/phwtHKNqzn49+9Vd2rMojlJLE2RNH0qZbe1wkwtxxz5M/d4VPrTjcSed243/uu4ZQUoh5r/yb2Yd8P31GDuLMy/oSKQ6ze9vXvDj2SbbnbgVgyB1X0LlvDywU4suPlvH6A8/40YTDJHfvRaPrboZQEgfee5sD/3jxsDIp3+9Dw+E/ARzh9WvY84eHvj3ZsBHNJz/Dwfkfs++pyZ7FXRv3PDyJDz+ZT8ujWvDG80/6HU61aUw3xixkXDz+Wv4y4mF2FhRyy/QJZM9aWCGpLn7zE+a9MBuAzhecxuB7r+Kv10z0K+QjspBx1kPXMPOKiezJ38awt8fz1bsL2bEqr6zM6jfmsuL5fwNwbL9T6T1uBP8a8QgnXXEeAK9dcCcNWjVj4HNjeOOi+yAO/qyykPHj8dfxpxET2FFQyC+nP8znsxayqdz3k5O9nt8Ovoui/Qc5a0Q/htx5Jc/cPJl2p55I+57f4zcDxwIw+tUH6NC7M6vnZfvVnBKhEI1uGM3u8bcTKdxC0988SVHWJ0Ryvvq2SFpbGlx8JV/ffTNuz26sWYsKVTS8/DqKs5d6HHjtDBvUjysuGcJdD/7W71BqJBIHPwdVqfFiX2b2bF0EUl2Z3Tuw9asCtm3cTLgozNIZczm5f88KZQ7s3lf2ul6j+nE5xtOm+wnsWr+JrzdsIVIUZs2b8ziu/2kVyhSVa0dKo/plSbVFx7bkfbocgP2Fuzi4ay9turX3LvgqHNe9A1u+KqCw9PtZNONTuhzy/ayem03R/oMArF+8ihapLUvPOFLqp5CckkxyvRSSkpP4essObxtwBEkdTiJSkEtkUz4UF1P08b+pd/pZFcrUv+CHHPjXG7g9uwFwu3Z8+/7jTyTUvCVFSxd4GXat9ezehebNmvodRo3Fcgn2ulBlT9fMph96CDjPzFoARHtYb11ofsxR7MwrLNvfmV9IZvcOh5U786p+nHP9RSSlJDPliocOO++3xmlHsTt/W9n+noJtHN3jhMPKdb7mArrccCGhesm8fenDAGxbsYHj+p3Kmjfm0iS9Fa27tKNxeiu2LFnrWfyVaX5MS3aU+3525G/juCN8P9/oPfw8Vry/BID1i1axam4247OexDA+evYdNq3Jq/S9Xgm1bENk65ay/ci2LSR1rLgSdyi9ZFWXphP+D0JJ7HtlKsVL5oMZDa+5kT2TJ5DSreIvVakbiT57IQPIBp4CHCVJtyfwu6reVH6Fzf4te9KtaeU/dHVl7nOzmPvcLLoP+T59b7mYab98wvMYYiH7mdlkPzObE4adSY+fD+OD2/7Mly9/QIsO6Vw880G+ztnKpoWrcOH4/od2JD2Hnc2xXY/nsUsfAKD1ccdwTId0xvW+EYAbn7+b408/ibVZ//EzzOoJJRFKy+Dr+24l1KoNTR98jF23XUe9c/tRtGgebtuW6HVITMT78EK0pNsTGE3JomtjnHNLzGyfc+6Dqt5UfoXNse0uj+n/gZ2bttM8vVXZfvO0VuzatL3S8ktnzOXih0bGMoSY2JO/nSZpLcv2G6e2ZE9+5e1Y8+Y8zn74Wj4AXDjCvAdeKDs35I372Lk2vy7Drbadm7bRotz30yKtJTs3bTus3IlnnUK/my/m/y59gPDBYgC6Djid9YtXc3Bvydp+K95fQrtTO/qedCPbthBq3aZsP9SyDa6wYhJ1hVsoXpUN4TCRzQWE8zYSSmtL0omdSenUlfoDh2ENGmLJybB/H/uer/UCtFKJeL+QVuWYrnMu4pz7PXAtcLeZ/RGfL77lLF1D63apHJXRhqSUJLoNPpPsWQsrlGndLrXs9Ul9e1C4vsDrMKPasnQtzdqn0jSzDaGUJE4Y2psNsxZVKNOs/TFlr489vzs715W0I6lBPZIb1geg7Q9OIVIcqXABzk8blq6hTbtUWpZ+P6cO/j5fHPL9tD25HZc+fANPXf8ouwt3lR3fnldIhzM6EUoKEUpOosMZnStcgPNLePWXhNIyCB2dCsnJpJzdl4MLPq1Q5uD8j0k+uTsA1rQ5SemZRDbls3fyBHb+9FJ2/ewy9j37BAc+eFcJt45FnKv25odqJVDnXA7wYzO7CNgVrXxdioQjvHnfVK5/9k5CSSGypr3PplU59L/tR+R8vo7s2Qv5/jX96XBWFyLFxezbuYdX4nBowYUjfHrvM1z4wtiS6VGvfMD2lbmcdvslbFm6jg2zFnHyT/rT9uyTiRSHObBzDx/c9mcAGrZuxoUv/AoXibC3YDvvj46f9kXCEV6772/87Nm7SqaMTZtDwaocLrztx2z8fC1fzF7I0DuvpH6j+vzkT7cCsD13K0/d8FuWzJxHx++fzK/eeRScY8UHS1n+3qKqP9ALkTB7n5pMk3sfhVCIg//+J5GN62lw2bWEV39J0YJPKV4yn5TuPWn2h6kQibD32Sdxu339Uam1MeMmkrV4GTt27OL8YSO4ceRVXDJ4gN9hRRXvPV2r6yv7sR5eiAcdi5P8DqFOfJFc7HcIMXf/afH3V04sNPnz036HUCdSWh9vta3juFZdq51zvipcVuvPq6mEm6crIlKVeJwiWp6SrogEim4DFhHxkHq6IiIeSvR5uiIiCSXeZy8o6YpIoCT6bcAiIglFY7oiIh7SmK6IiIfU0xUR8ZDm6YqIeEg9XRERD2n2goiIh3QhTUTEQ/E+vFDjhSlFROJZLBemNLOBZvalma02szuOcL6+mb1Sev4zM2sXrU4lXREJFOdctbeqmFkS8DhwIdAZuNzMOh9SbCSw3TnXAfg98Jto8SnpikigxHC5nl7AaufcWufcQeBlYOghZYYCz5S+fhU438yqfDB6nY/pPrL+Jc+ezG5mo0oXxQyUILYriG2CYLYr0dpUfDC32jmn/MrlpaaUa2tbYGO5cznAGYdUUVbGOVdsZjuBVsDWyj4zaD3dUdGLJKQgtiuIbYJgtiuIbQJKVi53zvUst9X5L5egJV0RkVjJBTLL7WeUHjtiGTNLBpoDhVVVqqQrInJkWUBHM2tvZvWAy4Dph5SZDlxT+vpHwL9dlCt0QZunmzDjTjUUxHYFsU0QzHYFsU1RlY7R3gy8AyQBTzvnlpvZeGCBc2468FfgOTNbDWyjJDFXqc6XYBcRkW9peEFExENKuiIiHgpE0o12q14iMrOnzWyzmX3hdyyxZGaZZjbHzLLNbLmZjfY7ptoyswZmNt/Mlpa26QG/Y4olM0sys8Vm9pbfsQRBwifdat6ql4imAgP9DqIOFAO/dM51BnoDNwXg+zoA9HXOdQO6AwPNrLe/IcXUaGCF30EERcInXap3q17Ccc59SMnV0EBxzuU75xaVvv6akh/mtv5GVTuuxO7S3ZTSLRBXqM0sA7gIeMrvWIIiCEn3SLfqJfQP8X+L0icy9QA+8zmUWiv9E3wJsBmY5ZxL+DaV+gMwFojvJ4MnkCAkXUlAZtYEeA241Tm3y+94ass5F3bOdafkrqVeZnaKzyHVmpn9ENjsnFvodyxBEoSkW51b9SSOmFkKJQn3Befc637HE0vOuR3AHIIxHn8WMMTM1lMybNfXzJ73N6TEF4SkW51b9SROlD727q/ACufcJL/jiQUza2NmLUpfNwT6Af/xNagYcM7d6ZzLcM61o+Tn6t/OuRE+h5XwEj7pOueKgW9u1VsBTHPOLfc3qtozs5eAucD3zCzHzEb6HVOMnAVcRUmvaUnpNsjvoGopDZhjZsso6QTMcs5pepUckW4DFhHxUML3dEVEEomSroiIh5R0RUQ8pKQrIuIhJV0REQ8p6YqIeEhJV0TEQ/8P6buxZB71xl8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Semantic Textual Similarity\n",
    "# Clustering\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sentence_transformers.util import cos_sim\n",
    "\n",
    "sim = np.zeros((len(sentences),len(sentences)))\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    sim[i:,i] = cos_sim(embedding[i],embedding[i:])\n",
    "print(sim)\n",
    "#plt.imshow(sim,cmap='hot',interpolation='nearest')\n",
    "sns.heatmap(sim,annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offshore-factor",
   "metadata": {},
   "source": [
    "### Training SBERT model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "perceived-greeting",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "amino-guide",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset snli (/home/majarall/.cache/huggingface/datasets/snli/plain_text/1.0.0/1f60b67533b65ae0275561ff7828aad5ee4282d0e6f844fd148d05d3c6ea251b)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['premise', 'hypothesis', 'label'],\n",
       "    num_rows: 550152\n",
       "})"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "snli = datasets.load_dataset('snli',split='train')\n",
    "\n",
    "snli "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "defensive-copyright",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99637ae18cb349ce88c8338a61c7ce95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/7.78k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30611e9375f34134847688f1c5f44cc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/4.47k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset glue/mnli (download: 298.29 MiB, generated: 78.65 MiB, post-processed: Unknown size, total: 376.95 MiB) to /home/majarall/.cache/huggingface/datasets/glue/mnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b22e20c53891407f8f96500aa58ee5e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/313M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d880db8457904d74bac61bc4d0975c07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53fb1646c48a4d9596662b5624908c0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation_matched split:   0%|          | 0/9815 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d166b240dfc7433d984eb196294fe5fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation_mismatched split:   0%|          | 0/9832 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b170e1058aff484990ba440a3ff3dba3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test_matched split:   0%|          | 0/9796 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9995075781aa4314b3bd87dee8734d66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test_mismatched split:   0%|          | 0/9847 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset glue downloaded and prepared to /home/majarall/.cache/huggingface/datasets/glue/mnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['premise', 'hypothesis', 'label', 'idx'],\n",
       "    num_rows: 392702\n",
       "})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnli = datasets.load_dataset('glue','mnli',split='train')\n",
    "\n",
    "mnli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "greater-publicity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['premise', 'hypothesis', 'label'],\n",
       "    num_rows: 392702\n",
       "})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnli "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "catholic-account",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b5d85d946c449058f6c9b4508d6d397",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/56 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#mnli = mnli.remove_columns(['idx'])\n",
    "\n",
    "snli = snli.cast(mnli.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "basic-humanity",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.concatenate_datasets([snli,mnli])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "chemical-period",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = snli "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "collective-meaning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f07791ad6a14ab3bc11b2bbcb778433",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/551 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.filter(\n",
    "    lambda x: False if x['label'] == -1 else True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "returning-invalid",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.select(range(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "legendary-summary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce92c658c2b64358b56d0314c259ef09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc063bd661754317af58a4594b3cde06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['label', 'premise_input_ids', 'premise_attention_mask', 'hypothesis_input_ids', 'hypothesis_attention_mask']\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "all_cols = ['label']\n",
    "\n",
    "for part in ['premise', 'hypothesis']:\n",
    "    dataset = dataset.map(\n",
    "        lambda x: tokenizer(\n",
    "            x[part], max_length=128, padding='max_length',\n",
    "            truncation=True\n",
    "        ), batched=True\n",
    "    )\n",
    "    for col in ['input_ids', 'attention_mask']:\n",
    "        dataset = dataset.rename_column(\n",
    "            col, part+'_'+col\n",
    "        )\n",
    "        all_cols.append(part+'_'+col)\n",
    "print(all_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "consecutive-clock",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "dataset.set_format(type='torch', columns=all_cols)\n",
    "\n",
    "# initialize the dataloader\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "capital-chair",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel\n",
    "\n",
    "# start from a pretrained bert-base-uncased model\n",
    "model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "subject-advancement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define mean pooling function\n",
    "def mean_pool(token_embeds, attention_mask):\n",
    "    # reshape attention_mask to cover 768-dimension embeddings\n",
    "    in_mask = attention_mask.unsqueeze(-1).expand(\n",
    "        token_embeds.size()).float()\n",
    "    # perform mean-pooling but exclude padding tokens (specified by in_mask)\n",
    "    pool = torch.sum(token_embeds * in_mask, 1) / torch.clamp(\n",
    "        in_mask.sum(1), min=1e-9\n",
    "    )\n",
    "    return pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "proud-bradley",
   "metadata": {},
   "outputs": [],
   "source": [
    "ffnn = torch.nn.Linear(768*3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "weekly-niger",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "# then later in the code add them to the process\n",
    "x = loss_func(x, label)  # label is our *true* 0, 1, 2 class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "opened-consultancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pytorch Training\n",
    "\n",
    "from transformers.optimization import get_linear_schedule_with_warmup\n",
    "\n",
    "# we would initialize everything first\n",
    "optim = torch.optim.Adam(model.parameters(), lr=2e-5)\n",
    "# and setup a warmup for the first ~10% steps\n",
    "total_steps = int(len(dataset) / batch_size)\n",
    "warmup_steps = int(0.1 * total_steps)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "\t\toptim, num_warmup_steps=warmup_steps,\n",
    "  \tnum_training_steps=total_steps - warmup_steps)\n",
    "# then during the training loop we update the scheduler per step\n",
    "scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "suffering-gross",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3fb0f6692c8492db36ed7b48028d130",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-997e1cd3d574>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m# using loss, calculate gradients and then optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# update learning rate scheduler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# 1 epoch should be enough, increase if wanted\n",
    "for epoch in range(1):\n",
    "    model.train()  # make sure model is in training mode\n",
    "    # initialize the dataloader loop with tqdm (tqdm == progress bar)\n",
    "    loop = tqdm(loader, leave=True)\n",
    "    for batch in loop:\n",
    "        # zero all gradients on each new step\n",
    "        optim.zero_grad()\n",
    "        # prepare batches and more all to the active device\n",
    "        inputs_ids_a = batch['premise_input_ids'].to(device)\n",
    "        inputs_ids_b = batch['hypothesis_input_ids'].to(device)\n",
    "        attention_a = batch['premise_attention_mask'].to(device)\n",
    "        attention_b = batch['hypothesis_attention_mask'].to(device)\n",
    "        label = batch['label'].to(device)\n",
    "        # extract token embeddings from BERT\n",
    "        u = model(\n",
    "            inputs_ids_a, attention_mask=attention_a\n",
    "        )[0]  # all token embeddings A\n",
    "        v = model(\n",
    "            inputs_ids_b, attention_mask=attention_b\n",
    "        )[0]  # all token embeddings B\n",
    "        # get the mean pooled vectors\n",
    "        u = mean_pool(u, attention_a)\n",
    "        v = mean_pool(v, attention_b)\n",
    "        # build the |u-v| tensor\n",
    "        uv = torch.sub(u, v)\n",
    "        uv_abs = torch.abs(uv)\n",
    "        # concatenate u, v, |u-v|\n",
    "        x = torch.cat([u, v, uv_abs], dim=-1)\n",
    "        # process concatenated tensor through FFNN\n",
    "        x = ffnn(x)\n",
    "        # calculate the 'softmax-loss' between predicted and true label\n",
    "        loss = loss_func(x, label)\n",
    "        # using loss, calculate gradients and then optimize\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        # update learning rate scheduler\n",
    "        scheduler.step()\n",
    "        # update the TDQM progress bar\n",
    "        loop.set_description(f'Epoch {epoch}')\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southwest-twenty",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mport sentence_transformers\n",
    "# do the same thing for using sBERT\n",
    "\n",
    "from sentence_transformers import InputExample\n",
    "from tqdm.auto import tqdm \n",
    "\n",
    "train_samples = []\n",
    "\n",
    "for row in tqdm(snli):\n",
    "  train_samples.append(InputExample(texts=[row['premise'],row['hypothesis']],\n",
    "                                    label=row['label']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
